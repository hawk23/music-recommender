% v2-acmsmall-sample.tex, dated March 6 2012
% This is a sample file for ACM small trim journals
%
% Compilation using 'acmsmall.cls' - version 1.3 (March 2012), Aptara Inc.
% (c) 2010 Association for Computing Machinery (ACM)
%
% Questions/Suggestions/Feedback should be addressed to => "acmtexsupport@aptaracorp.com".
% Users can also go through the FAQs available on the journal's submission webpage.
%
% Steps to compile: latex, bibtex, latex latex
%
% For tracking purposes => this is v1.3 - March 2012

\documentclass[prodmode,acmtecs]{acmsmall} % Aptara syntax

% Package to generate and customize Algorithm as per ACM style
\usepackage[ruled]{algorithm2e}

% Own packages
\usepackage[utf8]{inputenc} % for German quotation marks
\usepackage[ngerman]{babel} % for German Umlaute
\usepackage{listings} % for source code
\usepackage{amsmath} % eqref
\lstset{numbers=left, numberstyle=\tiny, numbersep=5pt} \lstset{language=Python}

\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}

% Metadata Information
\acmVolume{0}
\acmNumber{0}
\acmArticle{1}
\acmYear{2015}
\acmMonth{10}

% Copyright
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
%\doi{0000001.0000001}

%ISSN
%\issn{1234-56789}

% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{9} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{9}  % for normal

% Custom colors
\usepackage{color}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}

% Python style for highlighting
\newcommand\pythonstyle{\lstset{
language=Python,
basicstyle=\ttm,
otherkeywords={self},             % Add keywords here
keywordstyle=\ttb\color{deepblue},
emph={MyClass,__init__},          % Custom highlighting
emphstyle=\ttb\color{deepred},    % Custom highlighting style
stringstyle=\color{deepgreen},
frame=tb,                         % Any extra options here
showstringspaces=false            % 
}}


% Python environment
\lstnewenvironment{python}[1][]
{
\pythonstyle
\lstset{#1}
}
{}

% Python for external files
\newcommand\pythonexternal[2][]{{
\pythonstyle
\lstinputlisting[#1]{#2}}}

% Python for inline
\newcommand\pythoninline[1]{{\pythonstyle\lstinline!#1!}}

% Document starts
\begin{document}

% Page heads
\markboth{}{Music Similarity and Retrieval: Content- and Context-based Approaches}

% Title portion
\title{Report on practical exercises for \emph{Music Similarity and Retrieval: Content- and Context-based Approaches}}
\author{
Verena Dittmer
\affil{Alpe Adria University of Klagenfurt}
Mario Graf
\affil{Alpe Adria University of Klagenfurt}
Peter Luca Lidl
\affil{Alpe Adria University of Klagenfurt}
}

\begin{abstract}
TODO: Abstract
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002951.10003317.10003347.10003352</concept_id>
<concept_desc>Information systems~Information extraction</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[300]{Information systems~Information extraction}

%
% End generated code
%

% We no longer use \terms command
%\terms{Design, Algorithms, Performance}

\keywords{TODO, TODO, TODO}

\begin{bottomstuff}
This is a lot of bottom stuff.
\end{bottomstuff}

\maketitle


\section{Introduction}

\subsection{Problem Formulation}

\section{Similarity Miner}
%main methode ->  inputparameter
%Indexwörterbuch (welches)
%Term Weighting -> standard und alternativ
%Similarity Measure -> jaccard, cosine


\subsection{Preprocessing}
Für das Preprocessing, dass die HTML-Dokumente verarbeitet um zu einem Bag of Words für jeden Künstler zu gelangen, wurde der bereitgestellte Code verwendet. Dieser wurde um die Performance zu verbessern angepasst, sodass das Preprocessing mit Threads durchgeführt wird. Jeder \texttt{Prepocessing}-Thread erhält dabei den Dateipfad zu einem Künstler als Konstruktor-Argument. Das Ergebnis des Preprocessing wird in ein Dictionary mit dem Künstler als Key und den durch das Preprocessing erhaltenen Wörtern gespeichert. Aufgrunddessen das mehrere Threads auf das Dictionary zugreifen, wird dieses beim Schreiben des Ergebnisses durch ein \texttt{RLock}.

Aufgrund der Verwendung eines Musikwörterbuchs (später unser Term Index) müssen auch die Index Terme das Preprocessing durchlaufen, damit gleiche Terme korrekt erkannt werden. Andernfalls würden beispielsweise \glqq durchfuhrung\grqq (das Ergebnis des Preprocessing auf das Künstlerdokument) mit \glqq Durchfuhrung\grqq (aus dem Musikwörterbuch) verglichen werden.

\subsection{Term Weighting}
Um die Wichtigkeit von jedem Term für einen bestimmten Künstler zu bestimmen, wird das Term Weighting verwendet. Dabei wird mit der Weight Function Term Frequency-Inverse Document Frequency (TF-IDF) die Gewichtung bestimmt. Dafür werden für die Standard-TF-IDF zuerst die folgenden Parameter benötigt: $N$ als die Anzahl der Dokumente, $f_{d,t}$ als die Anzahl der Vorkomnisse eines Terms $t$ in einem Dokument $d$ und $f_t$ als die Anzahl der Dokumente, in dem der Term $t$ vorkommt. 

$N$ ist bei uns die Anzahl der Künstler, bzw. die Anzahl der HTML-Dokumente, da für jeden Künstler ein Dokument erstellt wurde. $f_{d,t}$ und $f_t$ müssen bestimmt werden. Hierfür wird die Klasse \texttt{TermCounter} verwendet. Diese zählt für jedes Dokument bzw. Künstler die Anzahl der  Vorkomnisse jedes Terms aus dem Term Index. Dies wird einem Dictionary \texttt{artists\_with\_terms\_count} gespeichert. Die Künstler als Keys haben jeweils ein Dictionary als Values. Dieses besteht wiederum aus den Terms aus den Term Index als Keys und den Anzahl der Vorkomnissen für diesen Künstler als Values. 
Somit kann man beispielsweise folgendermaßen auf den Vorkomnisse des Terms \glqq four\grqq vom Künstler \glqq Alicia Keys\grqq zugreifen:
\begin{python}
    print artists_with_terms_count['Alicia Keys']['four']
\end{python}

Zur Bestimmung von $f_t$ verwendet die statische Methode \texttt{count\_documents\_containing\_term(term)} in der Klasse \texttt{TermCounter} nun dieses Dictionary. Sie überprüft für jeden Artist, ob der Wert für den Term größer 0 ist, falls ja, so wird der Counter \texttt{count} um eins erhöht.
\begin{python}
    @staticmethod
    def count_documents_containing_term(term):
        count = 0
        for artist in artists_with_terms_count.keys():
            if term in artists_with_terms_count[artist] and artists_with_terms_count[artist][term] > 0:
                count += 1
        return count
\end{python}       

Nun können wir für jedes Dokument jedem Term im Term Index eine Gewichtung zuweisen. Dafür können verschiedene TF-IDF Funktionen verwendet werden. In unserer Implementierung wird die TF\_C mit der IDF\_B2 (die zumeist in der Praxis verwendet wird) standardmäßig verwendet. Als Alternative zu dieser Funktion wurde die TF\_C2 mit der IDF\_E implementiert. 

Die TF bezieht sich darum auf die zweite Monotonitäts Annahme: Die Wichtigkeit eines Terms für ein bestimmtes Dokument ist höher, wenn der Term öfters vorkommt.
Die Formel TF\_C \eqref{eq:TFC} und TF\_C2 \eqref{eq:TFC2} lauten wie folgt:
\begin{equation}\label{eq:TFC}
  r_{d,t} = 1 + log_{e} f_{d,t}
\end{equation}
\begin{equation}\label{eq:TFC2}
  r_{d,t} = log_{e} (1 + f_{d,t})
\end{equation}

Dabei sind die beiden Formeln sehr ähnlich: TF\_C hat jedoch den Nachteil, dass die Logarithmusfunktion für $f_dt$ gleich Null nicht definiert ist. In diesem Fall wird in der Implementierung für die Gewichtung dieses Terms Null zurückgegeben (da der Term somit auch nicht in dem Dokument vorkommt und keine Wichtigkeit hat). 

Die IDF behandelt die erste Monotonitäts Annahme: Seltene Terme sind nicht weniger wichtig als Häufige, was insofern bedeutet dass die Wichtigkeit eines Terms für ein Dokument höher ist, wenn der Term in nur wenigen Dokumenten vorkommt.
\begin{equation}\label{eq:IDFB2}
  w_{t} = log_{e} \frac{N}{f_{t}}
\end{equation}
\begin{equation}\label{eq:IDFC}
  w_{t} = \frac{1}{f_{t}}
\end{equation}
Beide Formeln beachten diese Monotonitäts Annahme: Ist bei IDF\_B2 \eqref{eq:IDFB2} $f_t$ kleiner, so wird die Gewichtung des IDF-Wertes logarithmisch größer. Ebenso gilt auch für IDF\_C \eqref{eq:IDFC}, dass wenn $f_t$ kleiner wird, so wird der IDF-Wert invers proportional größer und der Term somit wichtiger. Die beiden Funktionen unterscheiden sich prinzipiell in dem Logarithmus von IDF\_B2: Dies begründet sich auf Zipfs Gesetz, das besagt dass die Häufigkeit eines Wortes innerhalb eines Dokuments invers proportional zu dem Platz, in dem das Wort in der nach den Häufigkeiten sortierten Frequenztabelle ist. Die Verwendung des Logarithmus führt dazu, dass die Häufigkeiten von ganz wenigen Wörtern stark reduziert wird.

Die TF Formel wird mit der IDF Formel multipliziert und man erhält die Gewichtung. In der Klasse \texttt{WeightMeasurer} ist die Implementierung vorzufinden.  

\section{Similarity Computation}

 



\section{Music Recommendation}
In der Aufgabenstellung B wurde verlangt ein Musik Empfehlungssystem zu implementieren und zu evaluieren. Nachdem bereits ein großer Teil des Musik Empfehlungssystems vorgegeben wurde, haben wir uns auf die offenen Punkte fokussiert. Damit das Empfehlungssystem funktioniert, werden als erstes Eingabedaten gebraucht. Die bereitgestellte Datei seed\_users.txt stellt bereits einige Benutzernamen zur Verfügung, jedoch enthält diese nicht die empfohlene Benutzeranzahl von zumindest fünf hundert. Daher haben wir uns im ersten Schritt damit beschäftigt diese Mindestanforderungen zu erfüllen. Nachdem die Aufgabenstellung das Verwenden der LastFM API verlangte und keiner zuvor damit gearbeitet hat, haben wir uns einen Account angelegt und versucht einen API Schlüssel zu beantragen. Leider scheiterten wir bereits in diesem Schritt, da durch den derzeitigen Umbau der API einige Links nicht mehr verfügbar waren. Relativ bald haben wir jedoch einen alten API Schlüssel von einem anderen Programmierer im Internet gefunden und haben uns vorübergehend erlaubt diesen zu verwenden. Während dem Einarbeiten in die von der LastFM API bereitgestellten Funktionalität, haben wir bereits einige passende Funktionen für unsere Aufgabenstellung gefunden. Unter diesen Funktionen waren beispielsweise die folgenden:

\begin{itemize}
\item \textbf{Chart.GetTopArtists()} haben wir verwendet um eine eindeutige Liste von den in den Charts derzeit führenden Künstlern abzurufen.
\begin{python}
def lastfm_api_call_getTopArtists():
    content_merged = []        # empty list

    # Construct API call
    url = LASTFM_API_URL + "?method=chart.gettopartists" + \
          "&format=" + LASTFM_OUTPUT_FORMAT + \
          "&api_key=" + LASTFM_API_KEY + \
          "&limit=" + str(MAX_ARTISTS)

    content = urllib.urlopen(url).read()

    # Add retrieved content of current page to merged content variable
    content_merged.append(content)
    json_content = json.loads(content)

    artist_list = []

    for _artist in range(0, MAX_ARTISTS):
        artist_list.append((json_content["artists"]["artist"][_artist]["name"]).encode("utf-8"))

    return artist_list
\end{python}  

\item \textbf{Artist.GetTopFans()} haben wir verwendet um für einen angegeben Künstler eine eindeutige Liste von Fans (also Benutzern) abzurufen.
\begin{python}
def lastfm_api_call_getTopFans(artist_list):
    content_merged = []        # empty list
    user_list = ""

    # Construct API call
    for _artist in range(0, MAX_ARTISTS):
        url = LASTFM_API_URL + "?method=artist.gettopfans" + \
          "&api_key=" + LASTFM_API_KEY + \
          "&artist=" + artist_list[_artist] + \
          "&format=" + LASTFM_OUTPUT_FORMAT

        _content = urllib.urlopen(url).read()

        # Add retrieved content of current page to merged content variable
        content_merged.append(_content)
        json_content = json.loads(_content)

        for _user in range(0, MAX_FANS):
            user_list += (json_content["topfans"]["user"][_user]["name"]).encode("utf-8") + '\n'

    # Write content to local file
    output_file = "./users.txt"
    file_out = open(output_file, 'w')
    file_out.write(artist_lis
\end{python}

\item \textbf{User.GetFriends()} haben wir verwendet um für einen angegeben Benutzer eine eindeutige Liste von Freunden (also Benutzern) abzurufen.
\begin{python}
def lastfm_api_call_getFriends(user):
    content_merged = []         # empty list
    friend_list = []            # empty list

    # Construct API call
    url = LASTFM_API_URL + "?method=user.getfriends" + \
        "&api_key=" + LASTFM_API_KEY + \
        "&user=" + str(user) + \
        "&format=" + LASTFM_OUTPUT_FORMAT

    _content = urllib.urlopen(url).read()

    # Add retrieved content of current page to merged content variable
    content_merged.append(_content)
    json_content = json.loads(_content)

    if "friends" in json_content.keys():
        for _friend in json_content["friends"]["user"]:
            friend_list.append(_friend["name"].encode("utf-8"))

    return friend_list
\end{python}
\end{itemize}

Nach unseren ersten Testläufen mussten wir jedoch feststellen, dass gewisse von uns verwendete Methode keine validen Ergebnisse zurückliefern. Nach längerer Quellcodeanalyse und Recherche im Internet fanden wir heraus, dass der Fehler nicht in unserer Implementierung, sondern am derzeitigen Umbau der LastFM API lag. Gewisse verwendete Funktionen wurden nämlich noch nicht vollständig funktionsfähig portiert. Nach längerem Probieren, welche Funktionen nun wirklich verfügbar waren, hatten wir schlussendlich eine Datenbasis von xxx Usern und xxx Artists erstellt.

Bevor wir den Listening Event Fetcher erneut gestartet haben, wollten wir die Verteilung der Benutzer, bezüglich Herkunft, Alter sowie den Fakt ob diese häufig aktiv sind, berücksichtigen. Hiervon haben wir uns eine Verbesserung unseres Empfehlungssystems erhofft. Leider stießen wir auch hier auf viele Probleme mit Funktionen des LastFM Frameworks. Diese Funktionen sollten wichtige Informationen über Benutzer liefern. Ferner wurden viele Benutzer durch diese Klassifizierung unbrauchbar, da keine oder falsche Informationen vorlagen, wodurch wir entschieden diese Klassifizierung wieder zu entfernen.

\subsection{Validation}

Um die Qualität der Recommendations beurteilen zu können, haben wir eine Baseline-Methode implementiert. Die Baseline-Methode wählt für den User eine zufällige Anzahl an Artists, aus für die noch keine Listening-Events (für den betreffenden User) existieren.

\begin{python}
# This function defines a baseline recommender, which selects a random 
# number of artists the seed user hasn't listened yet and returns these. 
# Since this function is used with a cross fold validation all artists 
# not in the seed_aidx_train set are artists the user hasn't listened to.
def recommend_baseline (UAM, seed_uidx, seed_aidx_train):
    # UAM               user-artist-matrix
    # seed_uidx         user index of seed user

    # Get list of artist indices the user hasn't listened yet
    all_artists_idx = range(0, len(UAM[0,:]))
    not_listened = np.setdiff1d(all_artists_idx, seed_aidx_train)

    # get number of artists to recommend
    num_recommend = randint(1,len(not_listened))

    # recommend artists
    recommended_artists_idx = [not_listened[randint(0,len(not_listened)-1)] for _ in range(num_recommend)]

    # return result with possible duplicates removed
    return list(set(recommended_artists_idx))
\end{python}


% Start of "Sample References" section

\section{Typical references in new ACM Reference Format}
A paginated journal article \cite{Abril07}, an enumerated
journal article \cite{Cohen07}, a reference to an entire issue \cite{JCohen96}.

% Appendix
\appendix
\section*{APPENDIX}
\setcounter{section}{1}
TODO

% Bibliography
\bibliographystyle{ACM-Reference-Format-Journals}
\bibliography{msrcc-report-bibfile}
                             % Sample .bib file with references that match those in
                             % the 'Specifications Document (V1.5)' as well containing
                             % 'legacy' bibs and bibs with 'alternate codings'.
                             % Gerry Murray - March 2012


\medskip

\end{document}
% End of v2-acmsmall-sample.tex (March 2012) - Gerry Murray, ACM


